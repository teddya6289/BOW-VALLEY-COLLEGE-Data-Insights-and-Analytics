{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Data Wrangling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Balli\\AppData\\Local\\Temp\\ipykernel_8408\\969592043.py:2: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  bb_data =pd.read_csv(path +'/bb-data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 38 columns):\n",
      " #   Column                   Non-Null Count    Dtype  \n",
      "---  ------                   --------------    -----  \n",
      " 0   Unnamed: 0               1048575 non-null  int64  \n",
      " 1   tripduration             1048575 non-null  int64  \n",
      " 2   starttime                1048575 non-null  object \n",
      " 3   stoptime                 1048575 non-null  object \n",
      " 4   start station id         1048575 non-null  int64  \n",
      " 5   start station name       1048575 non-null  object \n",
      " 6   start station latitude   1048575 non-null  float64\n",
      " 7   start station longitude  1048575 non-null  float64\n",
      " 8   end station id           1048575 non-null  int64  \n",
      " 9   end station name         1048575 non-null  object \n",
      " 10  end station latitude     1048575 non-null  float64\n",
      " 11  end station longitude    1048575 non-null  float64\n",
      " 12  bikeid                   1048575 non-null  int64  \n",
      " 13  usertype                 1048575 non-null  object \n",
      " 14  birth year               1048575 non-null  int64  \n",
      " 15  gender                   1048575 non-null  int64  \n",
      " 16  temp                     1048575 non-null  float64\n",
      " 17  feelslike                1048575 non-null  float64\n",
      " 18  dew                      1048575 non-null  float64\n",
      " 19  humidity                 1048575 non-null  float64\n",
      " 20  precip                   1048575 non-null  float64\n",
      " 21  precipprob               1048575 non-null  int64  \n",
      " 22  preciptype               61979 non-null    object \n",
      " 23  snow                     1048575 non-null  int64  \n",
      " 24  snowdepth                1048575 non-null  int64  \n",
      " 25  windgust                 533226 non-null   float64\n",
      " 26  windspeed                1048575 non-null  float64\n",
      " 27  winddir                  1048575 non-null  float64\n",
      " 28  sealevelpressure         1048575 non-null  float64\n",
      " 29  cloudcover               1048575 non-null  float64\n",
      " 30  visibility               1048575 non-null  float64\n",
      " 31  solarradiation           1048575 non-null  float64\n",
      " 32  solarenergy              1048575 non-null  float64\n",
      " 33  uvindex                  1048575 non-null  int64  \n",
      " 34  severerisk               0 non-null        float64\n",
      " 35  conditions               1048575 non-null  object \n",
      " 36  icon                     1048575 non-null  object \n",
      " 37  stations                 1048575 non-null  object \n",
      "dtypes: float64(18), int64(11), object(9)\n",
      "memory usage: 304.0+ MB\n"
     ]
    }
   ],
   "source": [
    "path = os.path.abspath('C:/Users/Balli/Pictures/prediction')\n",
    "bb_data =pd.read_csv(path +'/bb-data.csv')\n",
    "bb_data.info()\n",
    "\n",
    "#FEATURE ENGINEERING\n",
    "\n",
    "# Converting tripduration hours to datetime\n",
    "bb_data['date']=pd.to_datetime(bb_data['tripduration'], unit ='s')\n",
    "\n",
    "# Separating the hour of the day from  datetime in other to determine lunch our\n",
    "# And also separating the date from date timee\n",
    "bb_data['hour_of_day'] = bb_data['date'].dt.hour\n",
    "bb_data['day_of_week'] = bb_data['date'].dt.dayofweek\n",
    "bb_data['month'] = bb_data['date'].dt.month\n",
    "bb_data['year'] = bb_data['date'].dt.year\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Handling possible outlier using the inter quartile range\n",
    "Q1=bb_data['temp'].quantile(0.25)\n",
    "Q3 = bb_data['temp'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Step 3: Calculate Lower Bound and Upper Bound\n",
    "lower_bound = Q1 - (1.5 * IQR)\n",
    "upper_bound = Q3 + (1.5 * IQR)\n",
    "\n",
    "# Calculate the mean\n",
    "t_mean = bb_data['temp'].mean()\n",
    "\n",
    "# Replace an number that falls below the lower bound and is above the upper bound with the mean of the data\n",
    "bb_data['c_temp']=bb_data['temp'].apply(lambda x: t_mean if x < lower_bound or x > upper_bound else x)\n",
    "\n",
    "\n",
    "# Handling possible outlier using the inter quartile range\n",
    "hQ1=bb_data['humidity'].quantile(0.25)\n",
    "hQ3 = bb_data['humidity'].quantile(0.75)\n",
    "hIQR = hQ3 - hQ1\n",
    "\n",
    "# Step 3: Calculate Lower Bound and Upper Bound\n",
    "hlower_bound = hQ1 - (1.5 * hIQR)\n",
    "hupper_bound = hQ3 + (1.5 * hIQR)\n",
    "\n",
    "# Calculate the mean\n",
    "h_mean = bb_data['humidity'].mean()\n",
    "\n",
    "# Replace an number that falls below the lower bound and is above the upper bound with the mean of the data\n",
    "bb_data['c_humidity']=bb_data['humidity'].apply(lambda x: h_mean if x < hlower_bound or x > hupper_bound else x)\n",
    "\n",
    "\n",
    "# Handling possible outlier using the inter quartile range\n",
    "wQ1=bb_data['windspeed'].quantile(0.25)\n",
    "wQ3 = bb_data['windspeed'].quantile(0.75)\n",
    "wIQR = wQ3 - wQ1\n",
    "\n",
    "# Step 3: Calculate Lower Bound and Upper Bound\n",
    "wlower_bound = wQ1 - (1.5 * wIQR)\n",
    "wupper_bound = wQ3 + (1.5 * wIQR)\n",
    "\n",
    "# Calculate the mean\n",
    "w_mean = bb_data['windspeed'].mean()\n",
    "# Replace an number that falls below the lower bound and is above the upper bound with the mean of the data\n",
    "bb_data['c_windspeed']=bb_data['windspeed'].apply(lambda x: w_mean if x < wlower_bound or x > wupper_bound else x)\n",
    "\n",
    "fQ1=bb_data['feelslike'].quantile(0.25)\n",
    "fQ3 = bb_data['feelslike'].quantile(0.75)\n",
    "fIQR = fQ3 - fQ1\n",
    "\n",
    "# Step 3: Calculate Lower Bound and Upper Bound\n",
    "flower_bound = fQ1 - (1.5 * fIQR)\n",
    "fupper_bound = fQ3 + (1.5 * fIQR)\n",
    "\n",
    "# Calculate the mean\n",
    "f_mean = bb_data['feelslike'].mean()\n",
    "# Replace an number that falls below the lower bound and is above the upper bound with the mean of the data\n",
    "bb_data['c_feelslike']=bb_data['feelslike'].apply(lambda x: f_mean if x < flower_bound or x > fupper_bound else x)\n",
    "\n",
    "dQ1=bb_data['dew'].quantile(0.25)\n",
    "dQ3 = bb_data['dew'].quantile(0.75)\n",
    "dIQR = dQ3 - dQ1\n",
    "\n",
    "# Step 3: Calculate Lower Bound and Upper Bound\n",
    "dlower_bound = dQ1 - (1.5 * dIQR)\n",
    "dupper_bound = dQ3 + (1.5 * dIQR)\n",
    "\n",
    "# Calculate the mean\n",
    "d_mean = bb_data['dew'].mean()\n",
    "# Replace an number that falls below the lower bound and is above the upper bound with the mean of the data\n",
    "bb_data['c_dew']=bb_data['dew'].apply(lambda x: d_mean if x < dlower_bound or x > dupper_bound else x)\n",
    "\n",
    "# Handling possible outlier using the inter quartile range\n",
    "wdQ1=bb_data['winddir'].quantile(0.25)\n",
    "wdQ3 = bb_data['winddir'].quantile(0.75)\n",
    "wdIQR = wdQ3 - wdQ1\n",
    "\n",
    "# Step 3: Calculate Lower Bound and Upper Bound\n",
    "lower_bound = wdQ1 - (1.5 * wdIQR)\n",
    "upper_bound = wdQ3 + (1.5 * wdIQR)\n",
    "\n",
    "# Calculate the mean\n",
    "wd_mean = bb_data['winddir'].mean()\n",
    "\n",
    "# Replace an number that falls below the lower bound and is above the upper bound with the mean of the data\n",
    "bb_data['c_winddir']=bb_data['winddir'].apply(lambda x: wd_mean if x < lower_bound or x > upper_bound else x)\n",
    "\n",
    "# Handling possible outlier using the inter quartile range\n",
    "vQ1=bb_data['visibility'].quantile(0.25)\n",
    "vQ3 = bb_data['visibility'].quantile(0.75)\n",
    "vIQR = vQ3 - vQ1\n",
    "\n",
    "# Step 3: Calculate Lower Bound and Upper Bound\n",
    "lower_bound = vQ1 - (1.5 * vIQR)\n",
    "upper_bound = vQ3 + (1.5 * vIQR)\n",
    "\n",
    "# Calculate the mean\n",
    "v_mean = bb_data['visibility'].mean()\n",
    "\n",
    "# Replace an number that falls below the lower bound and is above the upper bound with the mean of the data\n",
    "bb_data['c_visibility']=bb_data['visibility'].apply(lambda x: v_mean if x < lower_bound or x > upper_bound else x)\n",
    "\n",
    "# Handling possible outlier using the inter quartile range\n",
    "cQ1=bb_data['cloudcover'].quantile(0.25)\n",
    "cQ3 = bb_data['cloudcover'].quantile(0.75)\n",
    "cIQR = cQ3 - cQ1\n",
    "\n",
    "# Step 3: Calculate Lower Bound and Upper Bound\n",
    "lower_bound = cQ1 - (1.5 * cIQR)\n",
    "upper_bound = cQ3 + (1.5 * cIQR)\n",
    "\n",
    "# Calculate the mean\n",
    "c_mean = bb_data['cloudcover'].mean()\n",
    "\n",
    "# Replace an number that falls below the lower bound and is above the upper bound with the mean of the data\n",
    "bb_data['c_cloudcover']=bb_data['cloudcover'].apply(lambda x: c_mean if x < lower_bound or x > upper_bound else x)\n",
    "\n",
    "# Handling possible outlier using the inter quartile range\n",
    "sQ1=bb_data['solarradiation'].quantile(0.25)\n",
    "sQ3 = bb_data['solarradiation'].quantile(0.75)\n",
    "sIQR = sQ3 - sQ1\n",
    "\n",
    "# Step 3: Calculate Lower Bound and Upper Bound\n",
    "lower_bound = sQ1 - (1.5 * sIQR)\n",
    "upper_bound = sQ3 + (1.5 * sIQR)\n",
    "\n",
    "# Calculate the mean\n",
    "s_mean = bb_data['solarradiation'].mean()\n",
    "\n",
    "# Replace an number that falls below the lower bound and is above the upper bound with the mean of the data\n",
    "bb_data['c_solarradiation']=bb_data['solarradiation'].apply(lambda x: s_mean if x < lower_bound or x > upper_bound else x)\n",
    "\n",
    "# Handling possible outlier using the inter quartile range\n",
    "s1Q1=bb_data['solarenergy'].quantile(0.25)\n",
    "s1Q3 = bb_data['solarenergy'].quantile(0.75)\n",
    "s1IQR = s1Q3 - s1Q1\n",
    "# Step 3: Calculate Lower Bound and Upper Bound\n",
    "lower_bound = s1Q1 - (1.5 * s1IQR)\n",
    "upper_bound = s1Q3 + (1.5 * s1IQR)\n",
    "\n",
    "# Calculate the mean\n",
    "s1_mean = bb_data['solarenergy'].mean()\n",
    "\n",
    "# Replace an number that falls below the lower bound and is above the upper bound with the mean of the data\n",
    "bb_data['c_solarenergy']=bb_data['solarenergy'].apply(lambda x: s1_mean if x < lower_bound or x > upper_bound else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection and Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      month  day_of_week  hour_of_day     c_temp  c_feelslike  c_humidity  \\\n",
      "617       1            3            0  10.706801         21.8       16.16   \n",
      "804       1            3            0  21.100000         21.1       18.53   \n",
      "775       1            3            0  17.800000         17.8       55.77   \n",
      "603       1            3            0  10.600000         10.6       77.66   \n",
      "781       1            3            0  18.200000         18.2       52.95   \n",
      "...     ...          ...          ...        ...          ...         ...   \n",
      "2207      1            3            5   2.200000         -0.7       39.79   \n",
      "2206      1            3            5   1.400000         -3.0       34.88   \n",
      "2205      1            3            5   1.400000         -3.7       38.34   \n",
      "2204      1            3            5   0.800000         -4.0       34.66   \n",
      "3345      2            6           22  20.000000         20.0       20.49   \n",
      "\n",
      "      c_dew  c_windspeed  snow  c_winddir  c_visibility  c_cloudcover  \\\n",
      "617    -5.1    11.300000     0      248.0          16.0           2.3   \n",
      "804    -3.7    16.100000     0      217.0          16.0           2.3   \n",
      "775     8.8    14.100000     0      254.0          16.0          98.7   \n",
      "603     6.8    10.000000     0      258.0          16.0           7.5   \n",
      "781     8.4    13.800000     0      239.0          16.0          89.2   \n",
      "...     ...          ...   ...        ...           ...           ...   \n",
      "2207  -10.1    10.100000     0      266.0          16.0           4.4   \n",
      "2206  -12.5    16.900000     0       48.0          16.0          85.6   \n",
      "2205  -11.3    21.300000     0       51.0          16.0           2.3   \n",
      "2204  -13.0    18.900000     0       49.0          16.0           2.3   \n",
      "3345   -3.3    12.248224     0      287.0          16.0           2.3   \n",
      "\n",
      "      c_solarradiation  c_solarenergy  bikeid  \n",
      "617              389.0            1.4    8873  \n",
      "804              163.0            0.6    8774  \n",
      "775               37.0            0.1    7377  \n",
      "603              162.0            0.6    7346  \n",
      "781              154.0            0.6    7254  \n",
      "...                ...            ...     ...  \n",
      "2207               0.0            0.0       1  \n",
      "2206             216.0            0.8       1  \n",
      "2205             206.0            0.7       1  \n",
      "2204              45.0            0.2       1  \n",
      "3345             196.0            0.7       1  \n",
      "\n",
      "[3346 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "#Creating a dataframe  of feature important to our analysis(Feature Engineering)\n",
    "feature_dataset = bb_data[['month','day_of_week','hour_of_day','c_temp','c_humidity','c_windspeed',\n",
    "                           'c_feelslike','c_dew', 'snow','c_winddir','c_visibility','c_solarradiation',\n",
    "                           'c_solarenergy','c_cloudcover','bikeid']]\n",
    "\n",
    "# # NOW WE CAN DELVE INTO FEATURE SELECTION WHICH MEANS SELECTING ONLY THE COLUMNS THAT ARE \n",
    "# # IMPORTANT TO SOLVING OUR PROBLEM\n",
    "# ''' WEATHER PREDICTOR VARIABLE= TEMPERATURE, HUMIDITY, WINDSPEED, DEW, VISIBILITY, SOLARENERGY\n",
    "#     DATE PREDICTOR VARIABLE = MONTH,DAY OF WEEK, HOUR OF DAY\n",
    "#     DEPENDENT VARIABLE = BIKEID'''\n",
    "\n",
    "#Final dataset for our prediction\n",
    "pred_dataset = feature_dataset.groupby(['month','day_of_week','hour_of_day','c_temp','c_feelslike','c_humidity',\n",
    "'c_dew','c_windspeed','snow','c_winddir','c_visibility','c_cloudcover','c_solarradiation','c_solarenergy'] )['bikeid'].count().reset_index()\n",
    "\n",
    "grouped_dataset_model= pred_dataset.sort_values('bikeid', ascending=False)\n",
    "print(grouped_dataset_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# FEATURE EXTRACTION ND SETTING TARGET VARIABLE.\n",
    "and also Scaling Selected Feature to Permeat Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: X = independent variable[month, day of week, hour_of_Day,c_temp,c_humidity,c_windspeed, c_dew,c_visibility,c_solarenergy]\n",
    "#       Y = dependent variable  [bike_usage]\n",
    "\n",
    "ind_v = pred_dataset[['month','day_of_week','hour_of_day','c_temp', 'c_humidity','c_windspeed','c_dew',\n",
    "'c_visibility','c_solarenergy']]\n",
    "\n",
    "# USING THE STANDARD SCALER TO NORMALIZE THE INDEPENDENT VARIABLES TO AVOID SKEWED DATA\n",
    "scaler = StandardScaler()\n",
    "scaled_ind_v= scaler.fit_transform(ind_v)\n",
    "\n",
    "X = scaled_ind_v\n",
    "\n",
    "Y = pred_dataset['bikeid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOW SPLITTING OUR DATA IN TWO SET FOR TRAINING AND TESTING PURPOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING SET: Set of data our Model is going to learn from \n",
    "# TESTING SET : Set of data to test how well our model have learnt before deploying\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELLING\n",
    "I am using the NETELASTIC MODEL to fit our data to avoid possible overfitting, thereby enforcing regularization of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients of the independent variables:\n",
      "month : -3.2214826915572554\n",
      "day_of_week : -19.666807133301422\n",
      "hour_of_day : -171.6627702105404\n",
      "c_temp : 28.591042453915584\n",
      "c_humidity : -24.402022679137048\n",
      "c_windspeed : -4.768038490246373\n",
      "c_dew : 9.533176591336938\n",
      "c_visibility : 16.81905214189697\n",
      "c_solarenergy : 20.760010964530814\n",
      "     Bike Usage Prediction\n",
      "0               412.995497\n",
      "1               200.288265\n",
      "2               387.539629\n",
      "3               414.043782\n",
      "4               425.806660\n",
      "..                     ...\n",
      "665             420.650073\n",
      "666             371.532526\n",
      "667             456.677296\n",
      "668             152.472039\n",
      "669             232.925629\n",
      "\n",
      "[670 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
    "# Note alpha =1.0 indicates the strength of the regularization on our model \n",
    "# l1_ratio = 0.5 indicates equal proportion of the laso and ridge regularization models\n",
    "\n",
    "#Train Model\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#Make predictions\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Get the coefficients of the independent variables\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Display the coefficients\n",
    "print(\"Coefficients of the independent variables:\")\n",
    "for feature, coef in zip(ind_v.columns, coefficients):\n",
    "    print(f\"{feature} : {coef}\")\n",
    "\n",
    "prediction = pd.DataFrame(y_pred, columns =['Bike Usage Prediction'])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL-LIFE PREDICTION\n",
    "ANSWER TO QUESTION: PREDICTING THE NUMBER OF BIKES NEEDED AT LUNCH USING WEATHER AND DATE AS INDEPENDENT VARIABLE\n",
    "AND KNOWING THE NUMBER OF CHARGING STATIONS NEEDED\n",
    "FRIST LET CONSTRUCT A REAL-LIFE DATA TO TEST OUR MODEL I WILL BE USING TODAY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[314.1573071]\n"
     ]
    }
   ],
   "source": [
    "month = 8\n",
    "day_of_week =2\n",
    "hour_of_day = 12\n",
    "temperature = -22\n",
    "humidity = 38\n",
    "wind_speed =16\n",
    "dew = 4\n",
    "visibility = 14\n",
    "solarenery = 1.5\n",
    "\n",
    "new_data =[[month,day_of_week,hour_of_day,temperature,humidity,wind_speed, dew,\n",
    "            visibility,solarenery]]\n",
    "scaled_new_data =scaler.fit_transform(new_data)\n",
    "y_pred_r = model.predict(scaled_new_data)\n",
    "print(y_pred_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 481.5204175718372\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {mae}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
